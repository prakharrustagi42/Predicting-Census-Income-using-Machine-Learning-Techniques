{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca06858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25bed2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_income = pd.read_csv(\"census-income.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc5071a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   fnlwgt   education   education-num  \\\n",
       "0   39          State-gov    77516   Bachelors              13   \n",
       "1   50   Self-emp-not-inc    83311   Bachelors              13   \n",
       "2   38            Private   215646     HS-grad               9   \n",
       "3   53            Private   234721        11th               7   \n",
       "4   28            Private   338409   Bachelors              13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "    capital-gain   capital-loss   hours-per-week  native-country  income  \n",
       "0           2174              0               40   United-States   <=50K  \n",
       "1              0              0               13   United-States   <=50K  \n",
       "2              0              0               40   United-States   <=50K  \n",
       "3              0              0               40   United-States   <=50K  \n",
       "4              0              0               40            Cuba   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_income.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7757e2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', ' workclass', ' fnlwgt', ' education', ' education-num',\n",
       "       ' marital-status', ' occupation', ' relationship', ' race', ' sex',\n",
       "       ' capital-gain', ' capital-loss', ' hours-per-week', ' native-country',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_income.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4213c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_income.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "       'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9caceb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "census_income.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9e1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Replace all the missing values with NA. \n",
    "census_income.replace(\" ?\",np.NaN,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74686ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove all the rows that contain NA values. \n",
    "census_income.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3e95f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
       "       ' Local-gov', ' Self-emp-inc', ' Without-pay'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_income[\"workclass\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86def857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
       "       ' Local-gov', ' Self-emp-inc', ' Without-pay'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_income[\"workclass\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2d969",
   "metadata": {},
   "source": [
    "when dropping the na values, the \"never worked\" workclass was removed all together since they had \"?\" as their occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94607863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10be17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Extract the “education” column and store it in “census_ed” . \n",
    "# b) Extract all the columns from “age” to “relationship” and store it in “census_seq”. \n",
    "# c) Extract the column number “5”, “8”, “11” and store it in “census_col”. \n",
    "# d) Extract all the male employees who work in state-gov and store it in “male_gov”. \n",
    "# e) Extract all the 39 year olds who either have a bachelor's degree or who are \n",
    "# native of the United States and store the result in “census_us”. \n",
    "# f) Extract 200 random rows from the “census” data frame and store it in “census_200”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e53ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_ed = census_income[\"education\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d9b3032",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_seq = census_income.loc[:,\"age\":\"relationship\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3868256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_col = census_income.iloc[:,[4,7,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf9668fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_gov = census_income[(census_income[\"workclass\"]==\" State-gov\") & (census_income[\"sex\"]==\" Male\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1373a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_us = census_income[(census_income[\"age\"] == 39) & ((census_income[\"education\"] == \" Bachelors\") | (census_income[\"native-country\"] == \" United-States\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6301c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_200 = census_income.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ced92e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workclass\n",
       " Private             22286\n",
       " Self-emp-not-inc     2499\n",
       " Local-gov            2067\n",
       " State-gov            1279\n",
       " Self-emp-inc         1074\n",
       " Federal-gov           943\n",
       " Without-pay            14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g) Get the count of different levels of the “workclass” column. \n",
    "workclass_counts = census_income[\"workclass\"].value_counts()\n",
    "workclass_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4361ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(data = census_income, x= \"workclass\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf279e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workclass\n",
       " Federal-gov          832.321315\n",
       " Local-gov            829.230285\n",
       " Private              879.858207\n",
       " Self-emp-inc        4810.746741\n",
       " Self-emp-not-inc    1913.134454\n",
       " State-gov            684.306489\n",
       " Without-pay          487.857143\n",
       "Name: capital-gain, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h) Calculate the mean of the “capital.gain” column grouped according to “workclass”. \n",
    "\n",
    "capital_gain_mean = census_income.groupby(\"workclass\")[\"capital-gain\"].mean()\n",
    "capital_gain_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aa2acff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>209642</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>159449</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>280464</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>141297</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>India</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>193524</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32519</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>364548</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32532</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>204461</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32533</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>337992</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>Japan</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32554</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>321865</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6396 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt      education  education-num  \\\n",
       "7       52   Self-emp-not-inc  209642        HS-grad              9   \n",
       "9       42            Private  159449      Bachelors             13   \n",
       "10      37            Private  280464   Some-college             10   \n",
       "11      30          State-gov  141297      Bachelors             13   \n",
       "20      40            Private  193524      Doctorate             16   \n",
       "...    ...                ...     ...            ...            ...   \n",
       "32519   46            Private  364548   Some-college             10   \n",
       "32532   34            Private  204461      Doctorate             16   \n",
       "32533   54            Private  337992      Bachelors             13   \n",
       "32554   53            Private  321865        Masters             14   \n",
       "32557   40            Private  154374        HS-grad              9   \n",
       "\n",
       "            marital-status          occupation relationship  \\\n",
       "7       Married-civ-spouse     Exec-managerial      Husband   \n",
       "9       Married-civ-spouse     Exec-managerial      Husband   \n",
       "10      Married-civ-spouse     Exec-managerial      Husband   \n",
       "11      Married-civ-spouse      Prof-specialty      Husband   \n",
       "20      Married-civ-spouse      Prof-specialty      Husband   \n",
       "...                    ...                 ...          ...   \n",
       "32519   Married-civ-spouse     Exec-managerial      Husband   \n",
       "32532   Married-civ-spouse      Prof-specialty      Husband   \n",
       "32533   Married-civ-spouse     Exec-managerial      Husband   \n",
       "32554   Married-civ-spouse     Exec-managerial      Husband   \n",
       "32557   Married-civ-spouse   Machine-op-inspct      Husband   \n",
       "\n",
       "                      race    sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "7                    White   Male             0             0              45   \n",
       "9                    White   Male          5178             0              40   \n",
       "10                   Black   Male             0             0              80   \n",
       "11      Asian-Pac-Islander   Male             0             0              40   \n",
       "20                   White   Male             0             0              60   \n",
       "...                    ...    ...           ...           ...             ...   \n",
       "32519                White   Male             0             0              48   \n",
       "32532                White   Male             0             0              60   \n",
       "32533   Asian-Pac-Islander   Male             0             0              50   \n",
       "32554                White   Male             0             0              40   \n",
       "32557                White   Male             0             0              40   \n",
       "\n",
       "       native-country income  \n",
       "7       United-States   >50K  \n",
       "9       United-States   >50K  \n",
       "10      United-States   >50K  \n",
       "11              India   >50K  \n",
       "20      United-States   >50K  \n",
       "...               ...    ...  \n",
       "32519   United-States   >50K  \n",
       "32532   United-States   >50K  \n",
       "32533           Japan   >50K  \n",
       "32554   United-States   >50K  \n",
       "32557   United-States   >50K  \n",
       "\n",
       "[6396 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i) Create a separate dataframe with the details of males and females from the census \n",
    "# data that has income more than 50,000. \n",
    "\n",
    "census_50_over_male = census_income[(census_income[\"sex\"] == \" Male\") & (census_income[\"income\"] == \" >50K\")]\n",
    "census_50_over_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aad9b44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>45781</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>43</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>292175</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>51835</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>60</td>\n",
       "      <td>Honduras</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>169846</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>343591</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14344</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32513</th>\n",
       "      <td>46</td>\n",
       "      <td>Private</td>\n",
       "      <td>42972</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32536</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>160216</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32538</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>139180</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>15020</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32545</th>\n",
       "      <td>39</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>111499</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1112 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt     education  education-num  \\\n",
       "8       31            Private   45781       Masters             14   \n",
       "19      43   Self-emp-not-inc  292175       Masters             14   \n",
       "52      47            Private   51835   Prof-school             15   \n",
       "67      53            Private  169846       HS-grad              9   \n",
       "84      44            Private  343591       HS-grad              9   \n",
       "...    ...                ...     ...           ...            ...   \n",
       "32513   46            Private   42972       Masters             14   \n",
       "32536   34            Private  160216     Bachelors             13   \n",
       "32538   38            Private  139180     Bachelors             13   \n",
       "32545   39          Local-gov  111499    Assoc-acdm             12   \n",
       "32560   52       Self-emp-inc  287927       HS-grad              9   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "8            Never-married    Prof-specialty   Not-in-family   White   Female   \n",
       "19                Divorced   Exec-managerial       Unmarried   White   Female   \n",
       "52      Married-civ-spouse    Prof-specialty            Wife   White   Female   \n",
       "67      Married-civ-spouse      Adm-clerical            Wife   White   Female   \n",
       "84                Divorced      Craft-repair   Not-in-family   White   Female   \n",
       "...                    ...               ...             ...     ...      ...   \n",
       "32513   Married-civ-spouse    Prof-specialty            Wife   White   Female   \n",
       "32536        Never-married   Exec-managerial   Not-in-family   White   Female   \n",
       "32538             Divorced    Prof-specialty       Unmarried   Black   Female   \n",
       "32545   Married-civ-spouse      Adm-clerical            Wife   White   Female   \n",
       "32560   Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country income  \n",
       "8             14084             0              50   United-States   >50K  \n",
       "19                0             0              45   United-States   >50K  \n",
       "52                0          1902              60        Honduras   >50K  \n",
       "67                0             0              40   United-States   >50K  \n",
       "84            14344             0              40   United-States   >50K  \n",
       "...             ...           ...             ...             ...    ...  \n",
       "32513             0             0              22   United-States   >50K  \n",
       "32536             0             0              55   United-States   >50K  \n",
       "32538         15020             0              45   United-States   >50K  \n",
       "32545             0             0              20   United-States   >50K  \n",
       "32560         15024             0              40   United-States   >50K  \n",
       "\n",
       "[1112 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_50_over_female = census_income[(census_income[\"sex\"] == \" Female\") & (census_income[\"income\"] == \" >50K\")]\n",
    "census_50_over_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3cfc475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.70081559578277"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# j) Calculate the percentage of people from the United States who are private employees \n",
    "# and earn less than 50,000 annually.  \n",
    "\n",
    "filter_conditions = census_income[(census_income[\"workclass\"] == \" Private\") & (census_income[\"income\"] == \" <=50K\") & (census_income[\"native-country\"] == \" United-States\")]\n",
    "percentage_private = len(filter_conditions)/len(census_income)*100\n",
    "percentage_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa68abd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.92785624295471"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k) Calculate the percentage of married people in the census data. \n",
    "\n",
    "Married_percentage = census_income[census_income[\"marital-status\"].str.contains(\"Married\")][\"marital-status\"].count()/census_income[\"marital-status\"].count()*100\n",
    "Married_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f31786a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.361050328227571"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l) Calculate the percentage of high school graduates earning more than 50,000 \n",
    "# annually.\n",
    "\n",
    "filter_grad = census_income[(census_income[\"education\"] == \" HS-grad\") & (census_income[\"income\"] == \" >50K\")]\n",
    "\n",
    "percentage_grad = len(filter_grad)/len(census_income)* 100\n",
    "percentage_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7917b20e",
   "metadata": {},
   "source": [
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aab4c2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 3. Linear Regression: \n",
    "\n",
    "### a) Build a simple linear regression model as follows: \n",
    "\n",
    "● Divide the dataset into training and test sets in 70:30 ratio. \n",
    "● Build a linear model on the test set where the dependent variable is “hours.per.week” and the independent variable is “education.num”. \n",
    "● Predict the values on the train set and find the error in prediction.  \n",
    "● Find the root-mean-square error (RMSE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e33c0172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "X = census_income[[\"education-num\"]]\n",
    "y = census_income[[\"hours-per-week\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.30, random_state = 0)\n",
    "\n",
    "Model = LinearRegression()\n",
    "Model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a8e3ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       hours-per-week\n",
      "15977       -0.137610\n",
      "13574       19.146752\n",
      "23210       -8.137610\n",
      "9284        19.146752\n",
      "8841        11.146752\n",
      "...               ...\n",
      "14169       -5.147076\n",
      "21206        6.284200\n",
      "10646        1.999838\n",
      "11687       16.999838\n",
      "2976        -5.137610\n",
      "\n",
      "[21113 rows x 1 columns]\n",
      "\n",
      "The Mean squared error is 137.76014309500732\n",
      "The RMSE is 11.737126696726389\n"
     ]
    }
   ],
   "source": [
    "## train figures \n",
    "\n",
    "\n",
    "train_prediction = Model.predict(X_train)\n",
    "train_error = y_train - train_prediction\n",
    "print(train_error)\n",
    "\n",
    "## rmse train\n",
    "print(\"\")\n",
    "print(f\"The Mean squared error is {mean_squared_error(train_prediction, y_train)}\" )\n",
    "print(f\"The RMSE is {np.sqrt(mean_squared_error(train_prediction, y_train))}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "373b58df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       hours-per-week\n",
      "2135        -0.137610\n",
      "15639      -20.853248\n",
      "29059       -0.853248\n",
      "27523        7.431114\n",
      "9280        -0.853248\n",
      "...               ...\n",
      "16826       -0.137610\n",
      "25246       13.440580\n",
      "18980        7.862390\n",
      "953        -20.137610\n",
      "30925       -0.853248\n",
      "\n",
      "[9049 rows x 1 columns]\n",
      "\n",
      "The Mean squared error is 145.81515723280097\n",
      "The RMSE is 12.075394702981802\n"
     ]
    }
   ],
   "source": [
    "## test figures \n",
    "\n",
    "\n",
    "test_prediction = Model.predict(X_test)\n",
    "test_error = y_test - test_prediction\n",
    "print(test_error)\n",
    "\n",
    "## rmse test\n",
    "print(\"\")\n",
    "print(f\"The Mean squared error is {mean_squared_error(test_prediction, y_test)}\" )\n",
    "print(f\"The RMSE is {np.sqrt(mean_squared_error(test_prediction, y_test))}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae338f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.93123798156621"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_income[\"hours-per-week\"].mean()\n",
    "## the mean working hours is 40 so 12 hours is more than 25 percent error which is substantial!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546b3e69",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression: \n",
    "a) Build a simple logistic regression model as follows: \n",
    "● Divide the dataset into training and test sets in 65:35 ratio. \n",
    "● Build a logistic regression model where the dependent variable is \n",
    "“X”(yearly income) and the independent variable is “occupation”. \n",
    "● Predict the values on the test set. \n",
    "● Build a confusion matrix and find the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa54e250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation\n",
       " Prof-specialty       4038\n",
       " Craft-repair         4030\n",
       " Exec-managerial      3992\n",
       " Adm-clerical         3721\n",
       " Sales                3584\n",
       " Other-service        3212\n",
       " Machine-op-inspct    1966\n",
       " Transport-moving     1572\n",
       " Handlers-cleaners    1350\n",
       " Farming-fishing       989\n",
       " Tech-support          912\n",
       " Protective-serv       644\n",
       " Priv-house-serv       143\n",
       " Armed-Forces            9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_income[\"occupation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "076ac8b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.85      7882\n",
      "           1       0.00      0.00      0.00      2675\n",
      "\n",
      "    accuracy                           0.75     10557\n",
      "   macro avg       0.37      0.50      0.43     10557\n",
      "weighted avg       0.56      0.75      0.64     10557\n",
      "\n",
      "[[7882    0]\n",
      " [2675    0]]\n",
      "0.7466136212939282\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "lenc = LabelEncoder()\n",
    "census_income[\"income\"] = lenc.fit_transform(census_income[\"income\"])\n",
    "\n",
    "X= census_income[[\"occupation\"]] ## double braces because ohe expects a 2d array \n",
    "y = census_income[\"income\"] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.35, random_state = 42)\n",
    "\n",
    "\n",
    "## standardsclar not needed because just on einpit column\n",
    "## OHE since the occupation is a nominal categorical column\n",
    "\n",
    "ohe = OneHotEncoder(drop = \"first\")\n",
    "X_train = ohe.fit_transform(X_train)\n",
    "X_test =ohe.transform(X_test)\n",
    "\n",
    "\n",
    "Model = LogisticRegression()\n",
    "Model.fit(X_train, y_train)\n",
    "predictions = Model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "\n",
    "### the model is performing very bad even though the score is 75 percent because it is an unbalanced target label\n",
    "### and the model has just predicted all outputs to be zero \n",
    "\n",
    "print(predictions.sum()) ## all are zeros "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f097b5",
   "metadata": {},
   "source": [
    "## Multiple Logistic Regression \n",
    "\n",
    "● Divide the dataset into training and test sets in 80:20 ratio. \n",
    "● Build a logistic regression model where the dependent variable is \n",
    "“X”(yearly income) and independent variables are “age”, “workclass”, and \n",
    "“education”. \n",
    "● Predict the values on the test set. \n",
    "● Build a confusion matrix and find the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a47761fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.87      4503\n",
      "           1       0.65      0.28      0.39      1530\n",
      "\n",
      "    accuracy                           0.78      6033\n",
      "   macro avg       0.72      0.61      0.63      6033\n",
      "weighted avg       0.76      0.78      0.74      6033\n",
      "\n",
      "[[4277  226]\n",
      " [1106  424]]\n",
      "0.7792143212332173\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# lenc = LabelEncoder()\n",
    "# census_income[\"income\"] = lenc.fit_transform(census_income[\"income\"])\n",
    "\n",
    "X= census_income[[\"age\", \"workclass\", \"education\" ]] ## double braces because ohe expects a 2d array \n",
    "y = census_income[\"income\"]  \n",
    "\n",
    "\n",
    "X = pd.get_dummies(X, columns = [\"workclass\",\"education\"],drop_first = True )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "Model = LogisticRegression()\n",
    "Model.fit(X_train, y_train)\n",
    "predictions = Model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "\n",
    "## the accuracy has improved and we get some precision and recall for the 1 label class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1443de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86      4503\n",
      "           1       0.65      0.26      0.38      1530\n",
      "\n",
      "    accuracy                           0.78      6033\n",
      "   macro avg       0.72      0.61      0.62      6033\n",
      "weighted avg       0.76      0.78      0.74      6033\n",
      "\n",
      "[[4283  220]\n",
      " [1126  404]]\n",
      "0.7768937510359688\n"
     ]
    }
   ],
   "source": [
    "## same thing but just using column transformer for practice \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "# lenc = LabelEncoder()\n",
    "# census_income[\"income\"] = lenc.fit_transform(census_income[\"income\"])\n",
    "\n",
    "X= census_income[[\"age\", \"workclass\", \"education\" ]] ## double braces because ohe expects a 2d array \n",
    "y = census_income[\"income\"]  \n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "## we can see that here we need OHE for workclass and education \n",
    "transformer = ColumnTransformer( transformers = [\n",
    "    (\"tnf1\", OneHotEncoder(drop = \"first\", sparse = False), [\"workclass\", \"education\" ])\n",
    "], remainder = \"passthrough\")\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "Model = LogisticRegression()\n",
    "Model.fit(X_train, y_train)\n",
    "predictions = Model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "\n",
    "## the accuracy has improved and we get some precision and recall for the 1 label class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d1fa3",
   "metadata": {},
   "source": [
    "## 5. Decision Tree: \n",
    "a) Build a decision tree model as follows: \n",
    "● Divide the dataset into training and test sets in 70:30 ratio. \n",
    "● Build a decision tree model where the dependent variable is “X”(Yearly Income) \n",
    "and the rest of the variables as independent variables. \n",
    "● Predict the values on the test set. \n",
    "● Build a confusion matrix and calculate the accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4917f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      6767\n",
      "           1       0.62      0.64      0.63      2282\n",
      "\n",
      "    accuracy                           0.81      9049\n",
      "   macro avg       0.75      0.75      0.75      9049\n",
      "weighted avg       0.81      0.81      0.81      9049\n",
      "\n",
      "[[5866  901]\n",
      " [ 826 1456]]\n",
      "0.8091501823405901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# lenc = LabelEncoder()\n",
    "# census_income[\"income\"] = lenc.fit_transform(census_income[\"income\"])\n",
    "\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns = [\"income\"], axis = 1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "## we can see that here we need OHE for workclass and education \n",
    "transformer = ColumnTransformer( transformers = [\n",
    "    (\"tnf1\", OneHotEncoder(drop = \"first\", sparse = False), [\"workclass\", \"education\", \"marital-status\",\"sex\", \"race\"\n",
    "                                                             , \"occupation\", \"native-country\", \"relationship\"])\n",
    "], remainder = \"passthrough\")\n",
    "\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "predictions = dt.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "\n",
    "## the performance has improved a lot and specifically the precision and recall of the 1 class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f80e0e9",
   "metadata": {},
   "source": [
    "## 6. Random Forest: \n",
    "### a) Build a random forest model as follows: \n",
    "● Divide the dataset into training and test sets in 80:20 ratio. \n",
    "● Build a random forest model where the dependent variable is “X”(Yearly Income) \n",
    "and the rest of the variables as independent variables and number of trees as \n",
    "300. \n",
    "● Predict values on the test set \n",
    "● Build a confusion matrix and calculate the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51c07f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      6767\n",
      "           1       0.74      0.63      0.68      2282\n",
      "\n",
      "    accuracy                           0.85      9049\n",
      "   macro avg       0.81      0.78      0.79      9049\n",
      "weighted avg       0.85      0.85      0.85      9049\n",
      "\n",
      "[[6256  511]\n",
      " [ 836 1446]]\n",
      "0.8511437727925738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# lenc = LabelEncoder()\n",
    "# census_income[\"income\"] = lenc.fit_transform(census_income[\"income\"])\n",
    "\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns = [\"income\"], axis = 1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "## we can see that here we need OHE for workclass and education \n",
    "transformer = ColumnTransformer( transformers = [\n",
    "    (\"tnf1\", OneHotEncoder(drop = \"first\", sparse = False), [\"workclass\", \"education\", \"marital-status\",\"sex\", \"race\"\n",
    "                                                             , \"occupation\", \"native-country\", \"relationship\"])\n",
    "], remainder = \"passthrough\")\n",
    "\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 300)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "## metrics \n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "## the performance has imrpoved even more \n",
    "\n",
    "## also I tried with education as ordinal columns following a relation that more educated can get higher salaries but the \n",
    "## f1 score went down and the precision for class 1 went down \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81401ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      6767\n",
      "           1       0.74      0.64      0.69      2282\n",
      "\n",
      "    accuracy                           0.85      9049\n",
      "   macro avg       0.81      0.78      0.79      9049\n",
      "weighted avg       0.85      0.85      0.85      9049\n",
      "\n",
      "[[6250  517]\n",
      " [ 821 1461]]\n",
      "0.8521383578295945\n"
     ]
    }
   ],
   "source": [
    "### Now let's try the same thing with education as ordinal rather than a nominal category \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "# lenc = LabelEncoder()\n",
    "# census_income[\"income\"] = lenc.fit_transform(census_income[\"income\"])\n",
    "\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns = [\"income\"], axis = 1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "## we can see that here we need OHE for workclass and education \n",
    "transformer = ColumnTransformer( transformers = [\n",
    "    (\"tnf1\", OneHotEncoder(drop = \"first\", sparse = False), [\"workclass\", \"marital-status\",\"sex\", \"race\"\n",
    "                                                             , \"occupation\", \"native-country\", \"relationship\"]),\n",
    "    (\"tnf2\", OrdinalEncoder(categories = [[\" Preschool\", \" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" 10th\", \" 11th\", \" 12th\",\n",
    "                                          \" HS-grad\", \" Some-college\", \" Assoc-voc\",\" Assoc-acdm\", \" Bachelors\", \" Masters\",\n",
    "                                          \" Prof-school\",\" Doctorate\"]]), [\"education\"])\n",
    "], remainder = \"passthrough\")\n",
    "\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 300)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "## metrics \n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "\n",
    "## The performance has improved with precision and recall both improving for both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad66086d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "0    22654\n",
       "1     7508\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_income[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b90cdd1",
   "metadata": {},
   "source": [
    "## RANDOM FOREST WITH HYPER PARAMTER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2045f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.2s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=300; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=300; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=300; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=500; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=500; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=500; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=500; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=500; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.1s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=1000; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=1, max_features=log2, n_estimators=1000; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=300; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=500; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=1000; total time=   4.3s\n",
      "[CV] END criterion=gini, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=500; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.4s\n",
      "[CV] END criterion=gini, max_depth=3, max_features=log2, n_estimators=1000; total time=   5.2s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.3s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=300; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=300; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=500; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=500; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=500; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=500; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.1s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=500; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   6.3s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   6.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=300; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=500; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=500; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=500; total time=   2.3s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.9s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.9s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=200; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=300; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=500; total time=   2.4s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=500; total time=   1.7s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.3s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.4s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.6s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.4s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=sqrt, n_estimators=1000; total time=   3.3s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=200; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=300; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=300; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=500; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=500; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=500; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=500; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=500; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.2s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=1000; total time=   2.9s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END criterion=log_loss, max_depth=1, max_features=log2, n_estimators=1000; total time=   2.9s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.4s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.4s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.6s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.5s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=sqrt, n_estimators=1000; total time=   4.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=500; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.7s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.7s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.7s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.7s\n",
      "[CV] END criterion=log_loss, max_depth=2, max_features=log2, n_estimators=1000; total time=   3.9s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.7s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.7s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.3s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.4s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.5s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.4s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=sqrt, n_estimators=1000; total time=   5.2s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=500; total time=   2.3s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.6s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.6s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.7s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.7s\n",
      "[CV] END criterion=log_loss, max_depth=3, max_features=log2, n_estimators=1000; total time=   4.4s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88      6767\n",
      "           1       0.92      0.24      0.38      2282\n",
      "\n",
      "    accuracy                           0.80      9049\n",
      "   macro avg       0.86      0.61      0.63      9049\n",
      "weighted avg       0.83      0.80      0.75      9049\n",
      "\n",
      "[[6719   48]\n",
      " [1744  538]]\n",
      "0.8019670681843297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# lenc = LabelEncoder()\n",
    "# census_income[\"income\"] = lenc.fit_transform(census_income[\"income\"])\n",
    "\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns = [\"income\"], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "## we can see that here we need OHE for workclass and education \n",
    "transformer = ColumnTransformer( transformers = [\n",
    "    (\"tnf1\", OneHotEncoder(drop = \"first\", sparse = False), [\"workclass\", \"marital-status\",\"sex\", \"race\"\n",
    "                                                             , \"occupation\", \"native-country\", \"relationship\"]),\n",
    "    (\"tnf2\", OrdinalEncoder(categories = [[\" Preschool\", \" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" 10th\", \" 11th\", \" 12th\",\n",
    "                                          \" HS-grad\", \" Some-college\", \" Assoc-voc\",\" Assoc-acdm\", \" Bachelors\", \" Masters\",\n",
    "                                          \" Prof-school\",\" Doctorate\"]]), [\"education\"])\n",
    "], remainder = \"passthrough\")\n",
    "\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "parameters = { \n",
    "    \"criterion\" : [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"n_estimators\" : [100,200,300,500,1000],\n",
    "    \"max_depth\" : [1,2,3],\n",
    "    \"max_features\" : [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "Cv = GridSearchCV(estimator = rf, param_grid = parameters, cv = 5, verbose = 2, scoring =  \"balanced_accuracy\")\n",
    "\n",
    "Cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions = Cv.predict(X_test)\n",
    "\n",
    "## metrics \n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "## the performance has imrpoved even more \n",
    "\n",
    "## also I tried with education as ordinal columns following a relation that more educated can get higher salaries but the \n",
    "## f1 score went down and the precision for class 1 went down \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5f01e77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_parameteres_balanced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# best_parameteres_balanced = Cv.best_params_\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_parameteres_balanced\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_parameteres_balanced' is not defined"
     ]
    }
   ],
   "source": [
    "# best_parameteres_balanced = Cv.best_params_\n",
    "best_parameteres_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# lenc = LabelEncoder()\n",
    "# census_income[\"income\"] = lenc.fit_transform(census_income[\"income\"])\n",
    "\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns = [\"income\"], axis = 1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "## we can see that here we need OHE for workclass and education \n",
    "transformer = ColumnTransformer( transformers = [\n",
    "    (\"tnf1\", OneHotEncoder(drop = \"first\", sparse = False), [\"workclass\", \"education\", \"marital-status\",\"sex\", \"race\"\n",
    "                                                             , \"occupation\", \"native-country\", \"relationship\"])\n",
    "], remainder = \"passthrough\")\n",
    "\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "parameters = { \n",
    "    \"criterion\" : [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"n_estimators\" : [100,200,300,500,1000],\n",
    "    \"max_depth\" : [1,2,3],\n",
    "    \"max_features\" : [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "Cv = GridSearchCV(estimator = rf, param_grid = parameters, cv = 5, verbose = 2, scoring =  \"accuracy\")\n",
    "\n",
    "Cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions = Cv.predict(X_test)\n",
    "\n",
    "## metrics \n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "## the performance has imrpoved even more \n",
    "\n",
    "## also I tried with education as ordinal columns following a relation that more educated can get higher salaries but the \n",
    "## f1 score went down and the precision for class 1 went down \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957a385",
   "metadata": {},
   "source": [
    "## ADABOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# lenc = LabelEncoder()\n",
    "# census_income[\"income\"] = lenc.fit_transform(census_income[\"income\"])\n",
    "\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns = [\"income\"], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tnf1\", OneHotEncoder(drop=\"first\", sparse=False), \n",
    "         [\"workclass\", \"marital-status\", \"sex\", \"race\", \"occupation\", \"native-country\", \"relationship\"]),\n",
    "        (\"tnf2\", OrdinalEncoder(categories=[[\" Preschool\", \" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" 10th\", \n",
    "                                             \" 11th\", \" 12th\", \" HS-grad\", \" Some-college\", \" Assoc-voc\", \n",
    "                                             \" Assoc-acdm\", \" Bachelors\", \" Masters\", \" Prof-school\", \" Doctorate\"]]), \n",
    "         [\"education\"])\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=300, random_state=42)\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions = adaboost.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b455ced1",
   "metadata": {},
   "source": [
    "## ADABOOST WITH HYPER PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6338de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# lenc = LabelEncoder()\n",
    "# census_income[\"income\"] = lenc.fit_transform(census_income[\"income\"])\n",
    "\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns = [\"income\"], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tnf1\", OneHotEncoder(drop=\"first\", sparse=False), \n",
    "         [\"workclass\", \"marital-status\", \"sex\", \"race\", \"occupation\", \"native-country\", \"relationship\"]),\n",
    "        (\"tnf2\", OrdinalEncoder(categories=[[\" Preschool\", \" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" 10th\", \n",
    "                                             \" 11th\", \" 12th\", \" HS-grad\", \" Some-college\", \" Assoc-voc\", \n",
    "                                             \" Assoc-acdm\", \" Bachelors\", \" Masters\", \" Prof-school\", \" Doctorate\"]]), \n",
    "         [\"education\"])\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "parameters = { \n",
    "    \"n_estimators\" : [1,10,100,200,300,500,1000],\n",
    "    \"learning_rate\" : [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "    \"algorithm\" : ['SAMME.R', 'SAMME']\n",
    "}\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "cv = GridSearchCV(estimator=ab, param_grid = parameters,cv = 10, verbose = 5, scoring= \"accuracy\")\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions = cv.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c230fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", cv.best_params_)\n",
    "Best_paramters_adaboost = cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## best accuracy till now = 86.29 \n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa54bfb",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns=[\"income\"], axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tnf1\", OneHotEncoder(drop=\"first\", sparse=False), \n",
    "         [\"workclass\", \"marital-status\", \"sex\", \"race\", \"occupation\", \"native-country\", \"relationship\"]),\n",
    "        (\"tnf2\", OrdinalEncoder(categories=[[\" Preschool\", \" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" 10th\", \n",
    "                                             \" 11th\", \" 12th\", \" HS-grad\", \" Some-college\", \" Assoc-voc\", \n",
    "                                             \" Assoc-acdm\", \" Bachelors\", \" Masters\", \" Prof-school\", \" Doctorate\"]]), \n",
    "         [\"education\"])\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions = gb.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9b21c",
   "metadata": {},
   "source": [
    "## Gradient Boosting with Hyperparamter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86997d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns=[\"income\"], axis=1)\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tnf1\", OneHotEncoder(drop=\"first\", sparse=False), \n",
    "         [\"workclass\", \"marital-status\", \"sex\", \"race\", \"occupation\", \"native-country\", \"relationship\"]),\n",
    "        (\"tnf2\", OrdinalEncoder(categories=[[\" Preschool\", \" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" 10th\", \n",
    "                                             \" 11th\", \" 12th\", \" HS-grad\", \" Some-college\", \" Assoc-voc\", \n",
    "                                             \" Assoc-acdm\", \" Bachelors\", \" Masters\", \" Prof-school\", \" Doctorate\"]]), \n",
    "         [\"education\"])\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "parameters = { \n",
    "    \"n_estimators\": [100, 200, 300, 500],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"subsample\": [0.8, 0.9, 1.0],\n",
    "    \"min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "cv = GridSearchCV(estimator=gb, param_grid=parameters, cv=10, verbose=5, scoring=\"accuracy\")\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions = cv.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", cv.best_params_)\n",
    "Best_paramters_gradientboosting = cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a492167",
   "metadata": {},
   "source": [
    "## XGBOOST Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace74e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns=[\"income\"], axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tnf1\", OneHotEncoder(drop=\"first\", sparse=False), \n",
    "         [\"workclass\", \"marital-status\", \"sex\", \"race\", \"occupation\", \"native-country\", \"relationship\"]),\n",
    "        (\"tnf2\", OrdinalEncoder(categories=[[\" Preschool\", \" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" 10th\", \n",
    "                                             \" 11th\", \" 12th\", \" HS-grad\", \" Some-college\", \" Assoc-voc\", \n",
    "                                             \" Assoc-acdm\", \" Bachelors\", \" Masters\", \" Prof-school\", \" Doctorate\"]]), \n",
    "         [\"education\"])\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "# Initializing XGBoost Classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "# Fitting the model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "predictions = xgb.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de9963",
   "metadata": {},
   "source": [
    "## XGBOOST Classifier with HyperParamter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Target variable and features\n",
    "y = census_income[\"income\"]  \n",
    "X = census_income.drop(columns=[\"income\"], axis=1)\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Defining column transformer for preprocessing\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tnf1\", OneHotEncoder(drop=\"first\", sparse=False), \n",
    "         [\"workclass\", \"marital-status\", \"sex\", \"race\", \"occupation\", \"native-country\", \"relationship\"]),\n",
    "        (\"tnf2\", OrdinalEncoder(categories=[[\" Preschool\", \" 1st-4th\", \" 5th-6th\", \" 7th-8th\", \" 9th\", \" 10th\", \n",
    "                                             \" 11th\", \" 12th\", \" HS-grad\", \" Some-college\", \" Assoc-voc\", \n",
    "                                             \" Assoc-acdm\", \" Bachelors\", \" Masters\", \" Prof-school\", \" Doctorate\"]]), \n",
    "         [\"education\"])\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Applying transformations\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "# Defining parameter grid for GridSearchCV\n",
    "parameters = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"subsample\": [0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initializing XGBoost Classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "cv = GridSearchCV(estimator=xgb, param_grid=parameters, cv=10, verbose=5, scoring=\"accuracy\")\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "predictions = cv.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", cv.best_params_)\n",
    "Best_paramters_XGboost = cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85ad14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
